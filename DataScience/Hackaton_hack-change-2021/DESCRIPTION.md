[English version](#English-version)

[Русская версия](#Русская-версия)
___

## English version
**Task from Hackaton Hack&Change 2021**

Here is my solution to the first part (2.1-2.2) of the task from [Hackaton Hack&Change 2021](https://changellenge.com/event/hack-change-2021/), Data Engineering track.
The first part of the task was to tranform the input data with more than 10 million records, aggregate three new tables using Apache Spark under specified conditions. 
The whole task, input (datasets.zip) and obtained output (client_profile.zip) data are placed [here](https://drive.google.com/drive/folders/15KezolPDhMLGATN099njCkbMUyHy3CNJ?usp=sharing).
The transformation was carried out in Apache Spark using pyspark environment in Linux.

___
## Русская версия
**Задание с Хакатона Hack&Change 2021**

Здесь представлено мое решение первой части (2.1-2.2) задания с [Hackaton Hack&Change 2021](https://changellenge.com/event/hack-change-2021/), трек Data Engineering.
В первой части задания необходимо было выполнить трансформацию входных данных с более чем 10 млн записей, создать триновых аггрегированных таблицы по заданным условиям с использованием Apache Spark.
Полное задание, входные (datasets.zip) и полученные выходные (client_profile.zip) данные выложены [здесь](https://drive.google.com/drive/folders/15KezolPDhMLGATN099njCkbMUyHy3CNJ?usp=sharing).
Трансформация была выполнена в Apache Spark с использованием pyspark в Linux.
