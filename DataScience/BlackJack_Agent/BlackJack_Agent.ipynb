{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BlackJack_AgentNN",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1iybL9hkBPDzv0ZUzo0QGsdoFvJxrisuZ",
      "authorship_tag": "ABX9TyNISTa0MnhwEb0yCnIZb9x9"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCezrWzA9tcC"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from IPython.display import clear_output\n",
        "\n",
        "random.seed()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsfVxGb4kb1f"
      },
      "source": [
        "class BlackJack():\n",
        "    def __init__(self, n_decks, n_players, shuffle_every_round=False, shoe_limit=0.3, interactive=True):\n",
        "        self.deck_standard = [2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 10, 10, 11]\n",
        "        self.n_decks = n_decks\n",
        "        self.n_players = n_players\n",
        "        self.deck_game_start = []\n",
        "        for i in range(self.n_decks * 4):\n",
        "            self.deck_game_start.extend(self.deck_standard)\n",
        "        self.deck_game = self.deck_game_start.copy()\n",
        "        random.shuffle(self.deck_game)\n",
        "        self.shuffle_every_round = shuffle_every_round\n",
        "        self.shoe_limit = shoe_limit\n",
        "        self.interactive = interactive\n",
        "        self.player_number = 1\n",
        "    \n",
        "    def get_score(self, hand):\n",
        "        n_aces = hand.count(11)\n",
        "        s = sum(hand)\n",
        "        while s > 21 and n_aces > 0:\n",
        "            s -= 10\n",
        "            n_aces -= 1\n",
        "        return s\n",
        "    \n",
        "    def deal_cards(self):\n",
        "        self.hand_players = {i: [self.deck_game.pop() for k in range(2)] for i in range(1, self.n_players + 1)}\n",
        "        self.hand_dealer = [self.deck_game.pop()]\n",
        "        if self.interactive:\n",
        "            print('Players\\' hands:', self.hand_players)\n",
        "            print('Dealer\\'s hand:', self.hand_dealer)\n",
        "    \n",
        "    def player_choice(self, player, choice_ai='s'):\n",
        "        self.scores[player] = self.get_score(self.hand_players[player + 1])\n",
        "        if self.interactive: print('Hand:', self.hand_players[player + 1], ', Score:', self.scores[player])\n",
        "        if self.scores[player] == 21:\n",
        "            if self.interactive: print('BlackJack!')\n",
        "            self.rewards[player] = 0\n",
        "            return True\n",
        "        if self.scores[player] > 21:\n",
        "            if self.interactive: print('Player', player + 1, 'loses')\n",
        "            self.game_result[player] = -1\n",
        "            return True\n",
        "        if self.interactive == True:\n",
        "            choice = input()\n",
        "        else:\n",
        "            choice = choice_ai\n",
        "        if choice == 'h':\n",
        "            self.hand_players[player + 1].append(self.deck_game.pop())\n",
        "            return False\n",
        "        elif choice == 's':\n",
        "            return True\n",
        "        else:\n",
        "            if self.interactive: print('invalid')\n",
        "    \n",
        "    def dealer_choice(self):\n",
        "        self.scores[-1] = self.get_score(self.hand_dealer)\n",
        "        if self.interactive:\n",
        "            print('Dealer')\n",
        "            print('Hand:', self.hand_dealer, ', Score:', self.scores[-1])\n",
        "        while self.scores[-1] < 17:\n",
        "            self.hand_dealer.append(self.deck_game.pop())\n",
        "            self.scores[-1] = self.get_score(self.hand_dealer)\n",
        "            if self.interactive: print('Hand:', self.hand_dealer, ', Score:', self.scores[-1])\n",
        "        if self.scores[-1] > 21:\n",
        "            if self.interactive: print('Dealer busts')\n",
        "            self.game_result[-1] = -1\n",
        "            for player in range(self.n_players):\n",
        "                if self.game_result[player] != -1:\n",
        "                    self.game_result[player] = 1\n",
        "                    if self.rewards[player] != 0:\n",
        "                        self.rewards[player] = 1\n",
        "    \n",
        "    def get_result(self):\n",
        "        if self.game_result[-1] != -1:\n",
        "            for player in range(self.n_players):\n",
        "                if self.game_result[player] != -1 and self.scores[player] > self.scores[-1]:\n",
        "                    self.game_result[player] = 1\n",
        "                    if self.rewards[player] != 0:\n",
        "                        self.rewards[player] = 1\n",
        "                elif self.game_result[player] != -1 and self.scores[player] < self.scores[-1]:\n",
        "                    self.game_result[player] = -1\n",
        "                    if self.rewards[player] != 0:\n",
        "                        self.rewards[player] = -1\n",
        "                elif self.game_result[player] != -1 and self.scores[player] == self.scores[-1]:\n",
        "                    self.rewards[player] = 0.5\n",
        "\n",
        "        if self.interactive:\n",
        "            for player in range(self.n_players):\n",
        "                if self.game_result[player] == 1:\n",
        "                    print('Player', player + 1, 'won')\n",
        "                elif self.game_result[player] == -1:\n",
        "                    print('Player', player + 1, 'lost')\n",
        "                else:\n",
        "                    print('Player', player + 1, 'tie')\n",
        "        \n",
        "    def start(self):\n",
        "        self.scores = [0 for player in range(self.n_players + 1)]\n",
        "        self.game_result = [0 for player in range(self.n_players + 1)]\n",
        "        self.rewards = [-1 for player in range(self.n_players)]\n",
        "        if self.shuffle_every_round or (len(self.deck_game) <= len(self.deck_game_start) * self.shoe_limit):\n",
        "            self.deck_game = self.deck_game_start.copy()\n",
        "            random.shuffle(self.deck_game)\n",
        "        if self.interactive:\n",
        "            print('Number of cards in the full deck:', len(game.deck_game_start))\n",
        "            print('Current number of cards in the deck:', len(game.deck_game))\n",
        "            print('-----------------------')\n",
        "            print('Dealing')\n",
        "        self.deal_cards()\n",
        "        if self.interactive: print('-----------------------')\n",
        "\n",
        "    def play(self):\n",
        "        for player in range(self.n_players):\n",
        "            if self.interactive:\n",
        "                print('Player', player + 1)\n",
        "                print('For hit type \"h\", for stand type \"s\"')\n",
        "            while True:\n",
        "                player_done = self.player_choice(player)\n",
        "                if player_done == True:\n",
        "                    break\n",
        "            if self.interactive: print('-----------------------')\n",
        "        if np.abs(sum(self.game_result)) < self.n_players:\n",
        "            self.dealer_choice()\n",
        "            if self.interactive: print('-----------------------')\n",
        "        self.get_result()\n",
        "        if self.interactive: print('-----------------------')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T52W5qvreA0K",
        "outputId": "14ce0fca-6d31-4a58-a9d8-3ce6b9ce2457"
      },
      "source": [
        "game = BlackJack(n_decks=1, n_players=1, shuffle_every_round=True, shoe_limit=0.3)\n",
        "while True:\n",
        "    clear_output(wait=True)\n",
        "    game.start()\n",
        "    game.play()\n",
        "    print('Play again? (y/n)')\n",
        "    if input() != 'y':\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of cards in the full deck: 52\n",
            "Current number of cards in the deck: 52\n",
            "-----------------------\n",
            "Dealing\n",
            "Players' hands: {1: [10, 5]}\n",
            "Dealer's hand: [2]\n",
            "-----------------------\n",
            "Player 1\n",
            "For hit type \"h\", for stand type \"s\"\n",
            "Hand: [10, 5] , Score: 15\n",
            "h\n",
            "Hand: [10, 5, 2] , Score: 17\n",
            "h\n",
            "Hand: [10, 5, 2, 4] , Score: 21\n",
            "BlackJack!\n",
            "-----------------------\n",
            "Dealer\n",
            "Hand: [2] , Score: 2\n",
            "Hand: [2, 10] , Score: 12\n",
            "Hand: [2, 10, 10] , Score: 22\n",
            "Dealer busts\n",
            "-----------------------\n",
            "Player 1 won\n",
            "-----------------------\n",
            "Play again? (y/n)\n",
            "n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INGx0fnuUCVI"
      },
      "source": [
        "train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_4HRRqaO2vd",
        "outputId": "3954b134-2b59-44fe-8d9d-65a0f88d2716"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Configuration parameters for the whole setup\n",
        "seed = 42\n",
        "gamma = 0.99  # Discount factor for past rewards\n",
        "max_steps_per_episode = 10000\n",
        "game = BlackJack(n_decks=1, n_players=1, shuffle_every_round=True, shoe_limit=0.3, interactive=False)  # Create the environment\n",
        "eps = np.finfo(np.float32).eps.item()  # Smallest number such that 1.0 + eps != 1.0\n",
        "\n",
        "num_inputs = 7\n",
        "num_actions = 2\n",
        "num_hidden = 14\n",
        "\n",
        "inputs = layers.Input(shape=(num_inputs,))\n",
        "common = layers.Dense(num_hidden, activation=\"relu\")(inputs)\n",
        "action = layers.Dense(num_actions, activation=\"softmax\")(common)\n",
        "critic = layers.Dense(1)(common)\n",
        "\n",
        "model_1 = keras.Model(inputs=inputs, outputs=[action, critic])\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.1)\n",
        "huber_loss = keras.losses.Huber()\n",
        "action_probs_history = []\n",
        "critic_value_history = []\n",
        "rewards_history = []\n",
        "running_reward = 0\n",
        "episode_count = 0\n",
        "\n",
        "\n",
        "while True:  # Run until solved\n",
        "    game.start()\n",
        "    \n",
        "    episode_reward = 0\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        for player in range(game.n_players):\n",
        "            while True:\n",
        "                state = [game.n_decks,\n",
        "                        game.n_players,\n",
        "                        int(game.shuffle_every_round),\n",
        "                        sum(game.deck_game),\n",
        "                        player,\n",
        "                        sum(game.hand_players[game.player_number]),\n",
        "                        game.hand_dealer[0]]\n",
        "                state = tf.convert_to_tensor(state)\n",
        "                state = tf.expand_dims(state, 0)\n",
        "                action_probs, critic_value = model_1(state)\n",
        "                critic_value_history.append(critic_value[0, 0])\n",
        "                action = np.random.choice(num_actions, p=np.squeeze(action_probs))\n",
        "                action_probs_history.append(tf.math.log(action_probs[0, action]))\n",
        "                if action == 1:\n",
        "                    ai_action = 'h'\n",
        "                else:\n",
        "                    ai_action = 's'\n",
        "                player_done = game.player_choice(player=player, choice_ai=ai_action)\n",
        "                if player_done == True: break\n",
        "        if np.abs(sum(game.game_result)) < game.n_players:\n",
        "            game.dealer_choice()\n",
        "        game.get_result()\n",
        "        rewards = game.rewards\n",
        "        rewards_history.extend(rewards)\n",
        "        episode_reward += sum(rewards)\n",
        "\n",
        "        # Update running reward to check condition for solving\n",
        "        running_reward = 0.05 * episode_reward + (1 - 0.05) * running_reward\n",
        "\n",
        "        # Calculate expected value from rewards\n",
        "        # - At each timestep what was the total reward received after that timestep\n",
        "        # - Rewards in the past are discounted by multiplying them with gamma\n",
        "        # - These are the labels for our critic\n",
        "        returns = []\n",
        "        discounted_sum = 0\n",
        "        for r in rewards_history[::-1]:\n",
        "            discounted_sum = r + gamma * discounted_sum\n",
        "            returns.insert(0, discounted_sum)\n",
        "\n",
        "        # Normalize\n",
        "        returns = np.array(returns)\n",
        "        returns = (returns - np.mean(returns)) / (np.std(returns) + eps)\n",
        "        returns = returns.tolist()\n",
        "\n",
        "        # Calculating loss values to update our network\n",
        "        history = zip(action_probs_history, critic_value_history, returns)\n",
        "        actor_losses = []\n",
        "        critic_losses = []\n",
        "        for log_prob, value, ret in history:\n",
        "            # At this point in history, the critic estimated that we would get a\n",
        "            # total reward = `value` in the future. We took an action with log probability\n",
        "            # of `log_prob` and ended up recieving a total reward = `ret`.\n",
        "            # The actor must be updated so that it predicts an action that leads to\n",
        "            # high rewards (compared to critic's estimate) with high probability.\n",
        "            diff = ret - value\n",
        "            actor_losses.append(-log_prob * diff)  # actor loss\n",
        "\n",
        "            # The critic must be updated so that it predicts a better estimate of\n",
        "            # the future rewards.\n",
        "            critic_losses.append(\n",
        "                huber_loss(tf.expand_dims(value, 0), tf.expand_dims(ret, 0))\n",
        "            )\n",
        "\n",
        "        # Backpropagation\n",
        "        loss_value = sum(actor_losses) + sum(critic_losses)\n",
        "        grads = tape.gradient(loss_value, model_1.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(grads, model_1.trainable_variables))\n",
        "\n",
        "        # Clear the loss and reward history\n",
        "        action_probs_history.clear()\n",
        "        critic_value_history.clear()\n",
        "        # rewards_history.clear()\n",
        "\n",
        "    # Log details\n",
        "    episode_count += 1\n",
        "    if episode_count % 50 == 0:\n",
        "        template = \"running reward: {:.2f} at episode {}\"\n",
        "        print(template.format(running_reward, episode_count))\n",
        "\n",
        "    if running_reward > 100:  # Condition to consider the task solved\n",
        "        print(\"Solved at episode {}!\".format(episode_count))\n",
        "        break\n",
        "    \n",
        "    if episode_count >= 1000:  # Condition to consider the task solved\n",
        "        print(\"Solved at episode {}!\".format(episode_count))\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running reward: -0.68 at episode 50\n",
            "running reward: -0.78 at episode 100\n",
            "running reward: -0.90 at episode 150\n",
            "running reward: -0.91 at episode 200\n",
            "running reward: -0.87 at episode 250\n",
            "running reward: -0.89 at episode 300\n",
            "running reward: -0.85 at episode 350\n",
            "running reward: -0.85 at episode 400\n",
            "running reward: -0.76 at episode 450\n",
            "running reward: -0.78 at episode 500\n",
            "running reward: -0.92 at episode 550\n",
            "running reward: -0.74 at episode 600\n",
            "running reward: -0.85 at episode 650\n",
            "running reward: -0.86 at episode 700\n",
            "running reward: -0.73 at episode 750\n",
            "running reward: -0.93 at episode 800\n",
            "running reward: -0.83 at episode 850\n",
            "running reward: -0.84 at episode 900\n",
            "running reward: -0.91 at episode 950\n",
            "running reward: -0.78 at episode 1000\n",
            "Solved at episode 1000!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0FxM7C6R7mb",
        "outputId": "7dc4f4d5-b0ff-4850-e344-c1e05c9f3bd6"
      },
      "source": [
        "print(*rewards_history)\n",
        "print(*returns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 -1 -1 -1 0 -1 -1 -1 -1 -1 -1 -1 -1 -1 0 -1 0.5 -1 -1 -1 -1 -1 -1 -1 -1 -1 0 -1 -1 -1 -1 -1 -1 0 -1 0 -1 -1 -1 -1 -1 -1 -1 -1 0 0 -1 0.5 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 0 0 -1 -1 -1 0 -1 -1 -1 -1 0 0 -1 -1 -1 0 -1 -1 -1 -1 -1 0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 0 -1 0.5 -1 -1 -1 -1 0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 0 0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 0 -1 -1 -1 -1 -1 -1 0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 0 0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 0 -1 -1 -1 -1 0.5 -1 -1 -1 -1 -1 -1 -1 -1 -1 0 -1 -1 -1 0 0 -1 0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 0 -1 0 -1 0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 0 -1 -1 -1 -1 -1 0 -1 -1 -1 -1 -1 -1 -1 0 -1 0 0 -1 0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 0 -1 -1 -1 -1 0 -1 -1 0 0.5 -1 -1 -1 -1 -1 -1 0 -1 0 -1 -1 -1 0 -1 -1 -1 -1 0 0 -1 0 0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 0 -1 -1 -1 -1 -1 -1 -1 -1 0 -1 0 -1 -1 -1 -1 0 -1 -1 -1 -1 -1 -1 -1 0 -1 -1 -1 -1 -1 -1 -1 -1 -1 0.5 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 0 -1 -1 -1 -1 0.5 -1 -1 -1 -1 0 -1 -1 -1 -1 0.5 -1 -1 -1 -1 0 -1 -1 -1 -1 -1 -1 0 -1 -1 -1 -1 -1 -1 -1 -1 -1 0 0 -1 0.5 0 -1 -1 0.5 -1 -1 -1 -1 -1 -1 -1 -1 -1 0 0 -1 -1 -1 -1 -1 -1 -1 0 -1 -1 -1 -1 -1 -1 0.5 -1 -1 -1 -1 0 -1 -1 -1 -1 -1 -1 0.5 -1 0 -1 -1 0 0 -1 -1 0 0 -1 -1 0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 0 -1 -1 0 -1 -1 0.5 -1 -1 -1 -1 -1 0 -1 -1 -1 -1 -1 -1 -1 -1 0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 0.5 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 0 -1 -1 -1 0 0 -1 -1 -1 0 -1 -1 -1 -1 0 -1 -1 -1 0 0 -1 -1 -1 -1 0 -1 -1 -1 -1 -1 -1 0 -1 -1 0 -1 -1 0 0.5 0 0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 0 -1 -1 -1 0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 0.5 -1 -1 0 -1 -1 -1 -1 0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 0 -1 -1 -1 0 0 -1 -1 -1 -1 -1 -1 0 -1 -1 0 -1 -1 -1 -1 -1 -1 0 -1 -1 -1 -1 -1 -1 -1 -1 0 -1 0 -1 -1 -1 -1 0 0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 0 -1 -1 -1 -1 -1 -1 0 -1 0.5 -1 0 0 -1 -1 -1 -1 -1 -1 -1 0 -1 0 -1 -1 -1 -1 -1 0.5 0 0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 0 -1 0 -1 0 -1 -1 -1 -1 0.5 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 0 -1 0 0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 0 0 -1 -1 -1 -1 -1 0 -1 -1 -1 -1 0.5 -1 -1 0 0 -1 0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 0 0.5 -1 -1 -1 -1 -1 0 -1 -1 -1 -1 -1 0 0.5 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 0 -1 -1 -1 -1 -1 -1 -1 0 -1 0 -1 -1 -1 0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 0 -1 -1 -1 -1 -1 -1 0 -1 -1 -1 -1 -1 -1 -1 0 -1 0 -1 -1 -1 -1 -1 -1 0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 -1 -1 -1 -1 -1 -1 -1 -1 0 -1 -1 -1 -1 -1 0\n",
            "-0.5386838257314253 -0.590599030863498 -0.580476741491631 -0.5702522067725737 -0.5599243939250413 -0.6120541502509893 -0.6021485792567743 -0.5921429519898904 -0.5820362577809162 -0.5718274757516492 -0.561515574711986 -0.5510995130557609 -0.540578238655533 -0.5299506887563133 -0.5192157898682125 -0.5709343481733838 -0.5606134256430311 -0.6440310871430094 -0.6344485155113401 -0.6247691502268251 -0.6149920135758002 -0.6051161179687045 -0.5951404658403244 -0.5850640495490314 -0.5748858512749985 -0.564604842917389 -0.5542199859905106 -0.6062921220342916 -0.5963283487348571 -0.5862639312606812 -0.5760978530039371 -0.5658290870880341 -0.5554565962638904 -0.5449793328051586 -0.5969581289177739 -0.5869000728595869 -0.6393023107909344 -0.6296719737415668 -0.619944360560388 -0.6101184886602073 -0.6001933655287116 -0.5901679886282111 -0.5800413452943718 -0.5698124126339276 -0.559480157421358 -0.6116054265098944 -0.6642572134680126 -0.6548789461426564 -0.7392487846173783 -0.7306280079096921 -0.721920152649403 -0.7131243392551717 -0.7042396792609986 -0.6952652752264805 -0.686200220646159 -0.6770435998579558 -0.6677944879506792 -0.6584519506706025 -0.6490150443270906 -0.6394828156972804 -0.6298543019297952 -0.6201285304474867 -0.6103045188491956 -0.6003812748105181 -0.590357795983571 -0.64279496041112 -0.6331999026508452 -0.6235079251152144 -0.6137180488165976 -0.6038292848786002 -0.5938406344361786 -0.5837510885347433 -0.5735596280282428 -0.5632652234762223 -0.5528668350398376 -0.5423634123768224 -0.531753894535393 -0.5835991003624553 -0.635967995137266 -0.6263039781318009 -0.6165423447929469 -0.606682109097135 -0.6592841655763361 -0.6498556654439933 -0.6403319279365759 -0.6307119910603968 -0.6209948831046599 -0.6737415130586842 -0.727020937254669 -0.7182766469372581 -0.7094440304550252 -0.700522195624487 -0.7540721317655807 -0.7456010858371694 -0.7370444737882689 -0.7284014313146325 -0.7196710853816665 -0.7108525541362456 -0.7645068373330139 -0.7561411924709402 -0.7476910461456128 -0.7391555448068989 -0.7305338262829453 -0.7218250196930928 -0.713028245359909 -0.7041426147203296 -0.6951672302359057 -0.6861011853021437 -0.6769435641569297 -0.667693441788027 -0.6583498838396404 -0.6489119465180373 -0.6393786764962165 -0.6297491108176093 -0.6825841673141888 -0.673391020734753 -0.7579478498619201 -0.7495159526011482 -0.7409988846609747 -0.7323957857315068 -0.7237057868128526 -0.7774899006427171 -0.7692553978342767 -0.7609377182297916 -0.752536021659605 -0.7440494594674967 -0.7354771744249631 -0.7268183006446264 -0.7180719634927712 -0.7092372795009979 -0.7003133562769843 -0.6912992924143447 -0.6821941774015774 -0.6729970915300957 -0.6637071058013254 -0.6543232818328708 -0.6448446717637252 -0.6978322086739019 -0.7513549732296366 -0.7428564812554075 -0.7342721459279037 -0.7256011001425462 -0.7168424680361245 -0.7079953648983246 -0.6990588970823649 -0.6900321619147295 -0.6809142476039867 -0.6717042331486907 -0.6624011882443507 -0.6530041731894624 -0.6435122387905854 -0.6339244262664667 -0.6868016576665705 -0.6776511119997849 -0.6684081365787894 -0.6590717977697033 -0.6496411525080005 -0.6401152482032499 -0.6304931226428959 -0.6833356944104382 -0.6741501390137927 -0.6648718002293026 -0.65549974085103 -0.6460330142063104 -0.6364706640601285 -0.6268117245185304 -0.617055219931058 -0.6072001647921967 -0.5972455636418322 -0.5871904109646958 -0.5770336910888004 -0.6293362685982202 -0.6821671549713714 -0.6729697961460485 -0.6636795347063287 -0.6542954322419651 -0.6448165408638206 -0.635241903108119 -0.6255705518397329 -0.615801510154495 -0.6059337912805173 -0.5959663984785194 -0.5858983249411481 -0.575728553691278 -0.5654560574792873 -0.5550797986792971 -0.5445987291843575 -0.5340117903005805 -0.5233179126401997 -0.5125160160135521 -0.5016050093199684 -0.490583790437561 -0.479451246111897 -0.46820625184354936 -0.45684767177451097 -0.4453743585734623 -0.433785153319878 -0.4220788853869645 -0.4728162628387905 -0.4615042485373812 -0.4500779714652504 -0.43853627745299767 -0.42687800067294385 -0.5089447992944361 -0.49799771970469964 -0.48694006355345065 -0.4757707139057249 -0.46448854254438543 -0.4530924098561637 -0.4415811647165465 -0.42995364437349803 -0.41820867433001546 -0.40634506822548727 -0.45692351823123767 -0.44545097115601434 -0.43386253976690065 -0.4221570535152699 -0.4728952205441488 -0.5241458943106934 -0.5133523611352633 -0.565011692887577 -0.5546309455563573 -0.5441453421914888 -0.5335538236411165 -0.5228553200548826 -0.5120487507758584 -0.5011330242313892 -0.4901070378228348 -0.47896967781419414 -0.4677198192196075 -0.45635632568972145 -0.44487804939690767 -0.4332838309193177 -0.42157249912377226 -0.40974287104746404 -0.4603556422938401 -0.4489177631384416 -0.49992624036553485 -0.4888880642209611 -0.5403002818630289 -0.5296699243194406 -0.518932189426927 -0.5080859925658023 -0.4971302381606253 -0.4860638195695372 -0.47488561897247933 -0.4635945072582794 -0.4521893439106023 -0.44066897689274676 -0.42903224253127664 -0.41727796539847806 -0.405404958193631 -0.39341202162307864 -0.38129794427908625 -0.4316233930328526 -0.4198952891374441 -0.4080487195461221 -0.39608248763569626 -0.38399538469587197 -0.37178618980716077 -0.42201556023292747 -0.4101904075213583 -0.39824580882280325 -0.3861805576121416 -0.3739934351771297 -0.3616832104952993 -0.3492486401096122 -0.3366884680028574 -0.38656331598615645 -0.37438005979734723 -0.42463563093008627 -0.47539883409446837 -0.4641129063713997 -0.5152748698937751 -0.5043917304111033 -0.49339866022658607 -0.48229454892909374 -0.4710782748912232 -0.4597487051559999 -0.448304695322441 -0.4367450894299571 -0.42506871984158984 -0.41327440712606717 -0.4013609599386705 -0.3893271749008961 -0.3771718364789016 -0.3648937168607261 -0.35249157583226576 -0.3399641606520029 -0.327310205924464 -0.3145284334724047 -0.3016175522076986 -0.2885762580009248 -0.2754032335496377 -0.26209714824530767 -0.2486566580389133 -0.23508040530518165 -0.22136701870545314 -0.27007700356453607 -0.2567171179573266 -0.24322228401064983 -0.2295911386099663 -0.2158223048719026 -0.26447628252054567 -0.2510598239734974 -0.23750784564314578 -0.2863808691581654 -0.36702850483506433 -0.3546479273214958 -0.3421422934694067 -0.32951034008345775 -0.3167507912087619 -0.3038623580019989 -0.29084373860122803 -0.3402555085097639 -0.3276044966898797 -0.37738758738718897 -0.3651116470711175 -0.35271170735791313 -0.340186515728414 -0.39009669752712334 -0.37794913206094977 -0.36567886391329923 -0.3532846536631473 -0.340765249370065 -0.3906812769631344 -0.441101506855123 -0.4294691414831713 -0.48028116798647413 -0.5316064472827396 -0.5208882732282394 -0.5100618347893494 -0.49912603838643077 -0.4880797793935831 -0.47692194202707106 -0.4656513992326145 -0.4542670125715469 -0.44276763210582215 -0.4311520962818573 -0.419419231813206 -0.4075678535620434 -0.3955967644194553 -0.38350475518451715 -0.37129060444215517 -0.42151496895514434 -0.4096847597660218 -0.3977350535143825 -0.3856646431591912 -0.37347230946707927 -0.3611568208891881 -0.34871693343677235 -0.33615139055554444 -0.3234589229987488 -0.3732001392143297 -0.3608819014419658 -0.4110011275408118 -0.3990647179333628 -0.3870077385318984 -0.3748289714597127 -0.36252718653831306 -0.41266303167853624 -0.4007434089815686 -0.3887033860553393 -0.37654174673591545 -0.3642572625748808 -0.3518486927152503 -0.33931478376612856 -0.32665426967610695 -0.3764277621207521 -0.3641421265999687 -0.3517323937506926 -0.3391973100645551 -0.32653560937148696 -0.31374601271182245 -0.3008272282071101 -0.2877779509296234 -0.2745968627705461 -0.26128263230683124 -0.34167675043977747 -0.3290400945989843 -0.31627579576990045 -0.30338256462941143 -0.29035909883093797 -0.27720408287288417 -0.2639161879657586 -0.2504940718979553 -0.23693637890017422 -0.22324173950847606 -0.2094087704259526 -0.19543607438299926 -0.18132223999617753 -0.22962773214102536 -0.2158592680345878 -0.20195172853313648 -0.18790370883470012 -0.17371378994739106 -0.253223374319131 -0.23969325003267472 -0.22602645782413264 -0.21222161720944413 -0.19827733376026405 -0.24675408947848673 -0.23315861888050854 -0.2194258202966922 -0.20555430657566537 -0.19154267655442692 -0.2712323506898734 -0.2578841352556467 -0.24440108936248878 -0.23078185108657168 -0.21702504474726098 -0.26569117128353426 -0.2522869843401526 -0.2387474015690605 -0.22507105533563376 -0.21125656419075853 -0.19730253273128845 -0.18320755145909642 -0.2315320871540752 -0.2177828589568606 -0.20389474966674473 -0.18986635644440542 -0.17569626228042637 -0.16138303585216512 -0.14692523137917335 -0.13232138847716196 -0.11757003201048351 -0.10266967194313201 -0.1501806937036055 -0.19817162477479114 -0.18408542221010937 -0.263699770544099 -0.31283735895710807 -0.2999093961316416 -0.2868508478230898 -0.36750323075923036 -0.3551274484570178 -0.3426266582527623 -0.32999959744038304 -0.31724499055919203 -0.30436154926505954 -0.29134797220027936 -0.27820294486211716 -0.26492513947003415 -0.2515132148315665 -0.30052770672222645 -0.35003729449057 -0.33748508858968357 -0.32480609273020256 -0.3119990262054741 -0.29906259537241503 -0.2859954935208403 -0.27279640074147216 -0.25946398379261504 -0.3085587864808611 -0.2955876057515942 -0.2824854029947585 -0.2692508547555306 -0.25588262421085634 -0.24237936103441785 -0.22873970126023685 -0.30880510291796487 -0.2958364102335171 -0.28273672065326677 -0.2695047109762458 -0.2561390446358207 -0.3052002620800588 -0.2921951568618945 -0.279058686944557 -0.26578952541189255 -0.2523863319445546 -0.23884775268461728 -0.22517242009882266 -0.305201788613506 -0.29219669881487126 -0.34162213498819066 -0.3289849274761689 -0.3162200714034202 -0.365888167905917 -0.4160579623528833 -0.4041726318849498 -0.39216724757390564 -0.44260248727004353 -0.49354717383179886 -0.48244456267173275 -0.47122980392419156 -0.5224636553006355 -0.5116531298119726 -0.5007334070961514 -0.4897033841508768 -0.4785619468324177 -0.4673079697430651 -0.45594031611745695 -0.44445783770775105 -0.4328593746676444 -0.4211437554352132 -0.40930979661457617 -0.39735630285635637 -0.3852820667369424 -0.37308586863652465 -0.4233283671312755 -0.41151647509544653 -0.3995852710188519 -0.4500954402447371 -0.438553922684802 -0.4268958241394134 -0.5089628027959208 -0.49801590505973514 -0.486958432598941 -0.47578926849712894 -0.46450728455590506 -0.4531113411809316 -0.5041621777821914 -0.49316678888425075 -0.4820603354519875 -0.4708416956214183 -0.45950973619660135 -0.4480633125351698 -0.43650126843271364 -0.4248224360059906 -0.4130256355749572 -0.4636715660589844 -0.45226718108303143 -0.4407476002992404 -0.42911166011359286 -0.4173581851785959 -0.4054859882745586 -0.39349387018967186 -0.3813806195988777 -0.36914501294150953 -0.35678581429770345 -0.3443017752635561 -0.3316916348250231 -0.3189541192305457 -0.3999307776354487 -0.38788254631178326 -0.3757126156818185 -0.3634197564596318 -0.35100272694227136 -0.33846027288433117 -0.32579112737126054 -0.31299401069139104 -0.3000676302066744 -0.28701068022211224 -0.27382184185386765 -0.2604997828960454 -0.24704315768612325 -0.23345060696903036 -0.21972075775984554 -0.2058522232051138 -0.1918436024427579 -0.17769348046058092 -0.22596231846870535 -0.21215682998173982 -0.19821189211611784 -0.18412609629225762 -0.23245991021787418 -0.281281944486174 -0.2680352401003944 -0.2546547306198097 -0.24113906447780437 -0.2900487669709517 -0.2768906163476453 -0.26359955511198224 -0.250174240732524 -0.23661331711691036 -0.28547730499025026 -0.27227297798330025 -0.2589352739358761 -0.24546284560514428 -0.2944162226551334 -0.3438640782611829 -0.33124951664080826 -0.318507535206086 -0.3056368468881846 -0.29263615161757744 -0.34206602670809577 -0.32943330295082096 -0.31667297592327054 -0.30378375670352253 -0.29076434335024165 -0.2776134207711705 -0.2643296605902905 -0.3134736115290185 -0.3005520754972077 -0.2875000188994186 -0.33687801386147154 -0.32419288593402906 -0.3113796254012584 -0.3609988285097937 -0.4424001809478197 -0.4933428240113707 -0.5448000392270796 -0.5342151337780774 -0.5235233100922169 -0.5127234881873067 -0.501814577172246 -0.49079547513683097 -0.47966506904045225 -0.4684222345996662 -0.45706583617462926 -0.44559472665439026 -0.4340077473410172 -0.48486561834793446 -0.47367531470823393 -0.46237197769843563 -0.4509544655673261 -0.5019835155462258 -0.4909661199590333 -0.47983743754772706 -0.4685963442029737 -0.4572417044607984 -0.44577237138789433 -0.43418718646576915 -0.4224849794737237 -0.41066456837064697 -0.3987247591756198 -0.38666434584730996 -0.37448211016214805 -0.3621768215912776 -0.34974723717625694 -0.3371921014035094 -0.3245101460775009 -0.31170009019264394 -0.2987606398038999 -0.28569048789607754 -0.27248831425181236 -0.2591527853182115 -0.24568255407214962 -0.3259190956572708 -0.31312327158635117 -0.3001981967672405 -0.34970445615220025 -0.3371488882478959 -0.3244664964253668 -0.3116559996349326 -0.29871610388701997 -0.348207392636826 -0.33563670287883146 -0.3229390364566148 -0.3101131107776081 -0.2971576302937625 -0.28407128637068607 -0.2708527571554574 -0.25750070744310516 -0.2440137885417392 -0.23039063813631902 -0.216629880151046 -0.20273012461036627 -0.2512518580139437 -0.2377018194213742 -0.22401491175211183 -0.21018975249023145 -0.25878683567037325 -0.3078747984785966 -0.29489670877960994 -0.2817875272654817 -0.26854592977646313 -0.2551705787774545 -0.2416601232229003 -0.22801319842032072 -0.2767903164078369 -0.2634982420414685 -0.25007190429766235 -0.29907183749606087 -0.28600482899927054 -0.27280583051766377 -0.2594735088190711 -0.2460065172043311 -0.23240349537126076 -0.21866306927724974 -0.2673457415158459 -0.2539582674030941 -0.24043556627910231 -0.22677627221446345 -0.2129790054825053 -0.19904237241992154 -0.18496496528599848 -0.17074536212041985 -0.15638212659963288 -0.20443569840714174 -0.19041276931349313 -0.23881008498679895 -0.2251343719192075 -0.21132052033578216 -0.19736713489797914 -0.18327280617292518 -0.23159800100642702 -0.28041132912107536 -0.2671558306406989 -0.25376643823627876 -0.24024179944393503 -0.22658054813853765 -0.21278130439571127 -0.1988426743524528 -0.18476325006633268 -0.17054160937328205 -0.15617631574393864 -0.1416659181385408 -0.12700895086036107 -0.11220393340765408 -0.09724937032411182 -0.14470564156318125 -0.13007937856201832 -0.1153053755305408 -0.10038214014520974 -0.08530816500851213 -0.07008192749669621 -0.05470188960597291 -0.10172838831253644 -0.08666801164217489 -0.1652983457280032 -0.1508800898396166 -0.198878085518237 -0.24736090943603525 -0.23377156833257812 -0.22004496115736877 -0.20617970138442987 -0.19217438848247137 -0.17802760777342283 -0.1637379302895349 -0.14930391262904225 -0.1972859873257378 -0.18319083892823665 -0.23151520580977172 -0.21776580709392826 -0.20387752556277253 -0.18984895835958507 -0.17567868845737614 -0.16136528451575025 -0.24075013650939203 -0.2896559104372021 -0.33905568208145487 -0.3263925508026987 -0.3136015091069856 -0.3006812649699015 -0.28763051331628137 -0.27444793588838196 -0.2611322011127259 -0.24768196396559883 -0.2340958658371877 -0.22037253439434842 -0.20651058344198503 -0.19250861278303247 -0.17836520807701914 -0.22664083121258316 -0.21284219638969668 -0.261466071932459 -0.24801920721785473 -0.2969984061023156 -0.2839104538540733 -0.2706903000679695 -0.2573366093749354 -0.24384803291732587 -0.3240660439857318 -0.3112515022211601 -0.2983075206407845 -0.2852327917717187 -0.272025994934278 -0.25868579610858106 -0.24521084779979607 -0.23159978890203364 -0.21785124456085933 -0.20396382603442076 -0.18993613055316932 -0.17576674117816807 -0.16145422665796427 -0.146997141284021 -0.13239402474468503 -0.11764340197767874 -0.10274378302110714 -0.08769366286295363 -0.13505341180443572 -0.12032965153298202 -0.1680190569256765 -0.21619017348395386 -0.20228597646178853 -0.1882413330050562 -0.17405482446290232 -0.15972501785466567 -0.14525046572513392 -0.13062970599833376 -0.11586126182984934 -0.10094364145764273 -0.08587533805137369 -0.07065482956019231 -0.055280578558999295 -0.03975103209314747 -0.02406462152158013 -0.008219762358380662 0.007785145887275321 0.023951719872786485 0.04028159258542411 0.05677641350727983 0.07343784878188134 0.0902675813824892 0.1072673112820932 0.12443875562512778 0.1417836489009204 0.15930374311889245 0.17700080798553083 0.13231474056777112 0.08717729873165007 0.10414581365498317 0.12128572771895606 0.13859877222801942 0.15608669597454775 0.17375126541548527 0.12903237433540168 0.1464236678001866 0.16399063089592897 0.18173503806334596 0.19965868166679723 0.12392053640227199 0.14126019514045965 0.15877500194670996 0.11390483547805234 0.06858143500466096 0.08536211292065045 0.03975040211839681 0.05623985747997975 0.07289587299672985 0.08972013109445763 0.10671433119317282 0.12388018987874329 0.141219441076289 0.15873383622532558 0.17642514445667537 0.19429515277117032 0.2123456662201551 0.23057850808781633 0.2489955200753532 0.26759856248700614 0.286389514417969 0.30537027394419375 0.32454275831411794 0.34390890414232467 0.3634706676051597 0.32066813412295175 0.24615230656000342 0.26472662964321875 0.28348857215151674 0.3024400292306057 0.32158291516907983 0.3409191635917812 0.2978888371397413 0.3169857514409333 0.33627556386638013 0.35576022288198267 0.3754416966351171 0.39532197315343454 0.35284117003029997 0.27865032262803235 0.29755290849981386 0.31664642958242095 0.3359328145143477 0.35541401141528395 0.375091988082896 0.39496873219159473 0.41504625149331054 0.4353265740202964 0.4558117482899796 0.47650384351188135 0.49740494979663075 0.5185171783670846 0.539842661771584 0.561383554099361 0.5831420311981252 0.6051202908938463 0.6273205532127565 0.6497450606055954 0.6723960781741198 0.6952758938999022 0.7183868188754399 0.7417311875375989 0.7653113579034164 0.7891297118082821 0.8131886551465307 0.8374906181144584 0.8620380554557993 0.8868334467096792 0.9118792964610728 0.9371781345937941 0.9627325165460376 0.925983133053131 0.9514244341817313 0.9771227181500145 1.00308058074424 1.0293006439707306 1.0557855563207208 1.0825379930378827 1.1095606563885512 1.0742943854193063 1.1012337800061511 1.0658833991744578 1.092737834304284 1.119863526354613 1.1472632152943392 1.1123777782534356 1.1397018535759784 1.1673019296593552 1.1951807943900388 1.2233412638149717 1.251786182426015 1.2805184234472708 1.3095408891253073 1.3388565110223134 1.3684682503122185 1.3983790980797994 1.4285920756228105 1.4591102347571652 1.4899366581252005 1.4585125689916794 1.4893329553317805 1.5204646587056199 1.5519108237297001 1.5836746267843267 1.6157592763344542 1.6481680132537753 1.6183422206367046 1.6507770479025128 1.6835394996861572 1.7166328853262023 1.7500605475888742 1.7838258630057144 1.8179322422146442 1.8523831303044722 1.8246201166475093 1.859138559024538 1.8314437820213136 1.8660311503112088 1.9009678859575674 1.9362575179235866 1.971903610818555 2.0079097652579176 2.0442796182269705 2.0184549529328617 2.054931322949136 2.0917761411473927 2.1289931292264406 2.166586046478004 2.2045586901664516 2.2429148959123584 2.281658538079941 2.3207935301684075 2.360323825207263 2.4002534161556026 2.44058633630544 2.481326659689114 2.5224785014908053 2.5640460184622103 2.606033409342418 2.6484449152820213 2.628722929756145 2.671363622770634 2.7144350298559776 2.757941501659354 2.8018874327738756 2.8462772621824834 2.8911154737063303 2.93640659645769 2.982155205297448 3.028365921297203 3.0750434122060466 3.12219239292205 3.169817625968519 3.217923921975052 3.2665161401634704 3.3155991888386396 3.365178025884265 3.415257659263685 3.4658431475257254 3.5169396003156654 3.568552178891362 3.6206860966445915 3.673346619627651 3.726539067085287 3.78026881199199 3.83454128159472 3.8893619579611145 3.8821744880178555 3.8749144173680987 3.8675810126713746 3.860173533179734 3.8526912306629257 3.845133349332816 3.900061016282424 3.9555435081507135 4.011586429229795 4.068195440420786 4.125376259805625 4.183134663224655 4.241476484860039 4.300407617825073 4.297372124244076 4.35686785962713 4.416964562034256 4.477668301839434 4.538985210733552 4.6009214823437725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZO48TggBN3-"
      },
      "source": [
        "def win_rate():\n",
        "    i = 0\n",
        "    results = []\n",
        "    while i < 500:\n",
        "        game.start()\n",
        "        for player in range(game.n_players):\n",
        "            while True:\n",
        "                state = [game.n_decks,\n",
        "                        game.n_players,\n",
        "                        int(game.shuffle_every_round),\n",
        "                        sum(game.deck_game),\n",
        "                        player,\n",
        "                        sum(game.hand_players[game.player_number]),\n",
        "                        game.hand_dealer[0]]\n",
        "                state = tf.convert_to_tensor(state)\n",
        "                state = tf.expand_dims(state, 0)\n",
        "                action = model_1.predict(state)[-1][-1][0]\n",
        "                if action > 0.5:\n",
        "                    ai_action = 'h'\n",
        "                else:\n",
        "                    ai_action = 's'\n",
        "                player_done = game.player_choice(player=player, choice_ai=ai_action)\n",
        "                if player_done == True: break\n",
        "        if np.abs(sum(game.game_result)) < game.n_players:\n",
        "            game.dealer_choice()\n",
        "        game.get_result()\n",
        "        results.extend(game.game_result[:-1])\n",
        "        i += 1\n",
        "        if i % 50 == 0:\n",
        "            template = \"step {}\"\n",
        "            print(template.format(i))\n",
        "    return results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDL_IHzaDHFW",
        "outputId": "4dc21371-9532-4eae-cad5-104e8a095a09"
      },
      "source": [
        "results = win_rate()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 50\n",
            "step 100\n",
            "step 150\n",
            "step 200\n",
            "step 250\n",
            "step 300\n",
            "step 350\n",
            "step 400\n",
            "step 450\n",
            "step 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K16ue3pmDNo-",
        "outputId": "00389520-d455-4170-e539-1116b0e2f6e6"
      },
      "source": [
        "print('Agent in general')\n",
        "print('Win rate:', results.count(1) / len(results) * 100)\n",
        "print('Lose rate:', results.count(-1) / len(results) * 100)\n",
        "print('Tie rate:', results.count(0) / len(results) * 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent in general\n",
            "Win rate: 38.4\n",
            "Lose rate: 56.599999999999994\n",
            "Tie rate: 5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHZoDxd6GyFA",
        "outputId": "6fa4f98a-16ef-4531-b95e-9994e676982e"
      },
      "source": [
        "print('Win rate:', results[::4].count(1) / len(results[::4]) * 100)\n",
        "print('Lose rate:', results[::4].count(-1) / len(results[::4]) * 100)\n",
        "print('Tie rate:', results[::4].count(0) / len(results[::4]) * 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Win rate: 38.4\n",
            "Lose rate: 56.8\n",
            "Tie rate: 4.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ohi2WH1rG9I5",
        "outputId": "5f69cf06-cf4a-4381-940a-24993d2eb4d5"
      },
      "source": [
        "print('Win rate:', results[1::4].count(1) / len(results[1::4]) * 100)\n",
        "print('Lose rate:', results[1::4].count(-1) / len(results[1::4]) * 100)\n",
        "print('Tie rate:', results[1::4].count(0) / len(results[1::4]) * 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Win rate: 35.199999999999996\n",
            "Lose rate: 60.0\n",
            "Tie rate: 4.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r93joQp6HDQQ",
        "outputId": "c8df212b-71a7-4b58-8b58-cc636e8b52cd"
      },
      "source": [
        "print('Win rate:', results[2::4].count(1) / len(results[2::4]) * 100)\n",
        "print('Lose rate:', results[2::4].count(-1) / len(results[2::4]) * 100)\n",
        "print('Tie rate:', results[2::4].count(0) / len(results[2::4]) * 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Win rate: 38.4\n",
            "Lose rate: 52.800000000000004\n",
            "Tie rate: 8.799999999999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQFfSY11HGcI"
      },
      "source": [
        "print('Win rate:', results[3::4].count(1) / len(results[3::4]) * 100)\n",
        "print('Lose rate:', results[3::4].count(-1) / len(results[3::4]) * 100)\n",
        "print('Tie rate:', results[3::4].count(0) / len(results[3::4]) * 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYvkoCx4K1nd"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Configuration parameters for the whole setup\n",
        "seed = 42\n",
        "gamma = 0.99  # Discount factor for past rewards\n",
        "max_steps_per_episode = 10000\n",
        "game = BlackJack(n_decks=1, n_players=1, shuffle_every_round=True, shoe_limit=0.3, interactive=False)  # Create the environment\n",
        "eps = np.finfo(np.float32).eps.item()  # Smallest number such that 1.0 + eps != 1.0\n",
        "\n",
        "num_inputs = 7\n",
        "num_actions = 2\n",
        "num_hidden = 14\n",
        "\n",
        "inputs = layers.Input(shape=(num_inputs,))\n",
        "common = layers.Dense(num_hidden, activation=\"relu\")(inputs)\n",
        "action = layers.Dense(num_actions, activation=\"softmax\")(common)\n",
        "critic = layers.Dense(1)(common)\n",
        "\n",
        "model_1 = keras.Model(inputs=inputs, outputs=[action, critic])\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.1)\n",
        "huber_loss = keras.losses.Huber()\n",
        "action_probs_history = []\n",
        "critic_value_history = []\n",
        "rewards_history = []\n",
        "running_reward = 0\n",
        "episode_count = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZMhDCBI9Kror",
        "outputId": "dff01c2f-2610-40c1-9776-b94f44818415"
      },
      "source": [
        "game.start()\n",
        "\n",
        "episode_reward = 0\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    for player in range(game.n_players):\n",
        "        while True:\n",
        "            state = [game.n_decks,\n",
        "                    game.n_players,\n",
        "                    int(game.shuffle_every_round),\n",
        "                    sum(game.deck_game),\n",
        "                    player,\n",
        "                    sum(game.hand_players[game.player_number]),\n",
        "                    game.hand_dealer[0]]\n",
        "            state = tf.convert_to_tensor(state)\n",
        "            state = tf.expand_dims(state, 0)\n",
        "            action_probs, critic_value = model_1(state)\n",
        "            critic_value_history.append(critic_value[0, 0])\n",
        "            action = np.random.choice(num_actions, p=np.squeeze(action_probs))\n",
        "            action_probs_history.append(tf.math.log(action_probs[0, action]))\n",
        "            if action == 1:\n",
        "                ai_action = 'h'\n",
        "            else:\n",
        "                ai_action = 's'\n",
        "            player_done = game.player_choice(player=player, choice_ai=ai_action)\n",
        "            if player_done == True: break\n",
        "    if np.abs(sum(game.game_result)) < game.n_players:\n",
        "        game.dealer_choice()\n",
        "    game.get_result()\n",
        "    rewards = game.rewards\n",
        "    rewards_history.extend(rewards)\n",
        "    episode_reward += sum(rewards)\n",
        "\n",
        "    # Update running reward to check condition for solving\n",
        "    running_reward = 0.05 * episode_reward + (1 - 0.05) * running_reward\n",
        "\n",
        "    # Calculate expected value from rewards\n",
        "    # - At each timestep what was the total reward received after that timestep\n",
        "    # - Rewards in the past are discounted by multiplying them with gamma\n",
        "    # - These are the labels for our critic\n",
        "    returns = []\n",
        "    discounted_sum = 0\n",
        "    for r in rewards_history[::-1]:\n",
        "        discounted_sum = r + gamma * discounted_sum\n",
        "        returns.insert(0, discounted_sum)\n",
        "\n",
        "    # Normalize\n",
        "    returns = np.array(returns)\n",
        "    returns = (returns - np.mean(returns)) / (np.std(returns) + eps)\n",
        "    returns = returns.tolist()\n",
        "\n",
        "    # Calculating loss values to update our network\n",
        "    history = zip(action_probs_history, critic_value_history, returns)\n",
        "    actor_losses = []\n",
        "    critic_losses = []\n",
        "    for log_prob, value, ret in history:\n",
        "        # At this point in history, the critic estimated that we would get a\n",
        "        # total reward = `value` in the future. We took an action with log probability\n",
        "        # of `log_prob` and ended up recieving a total reward = `ret`.\n",
        "        # The actor must be updated so that it predicts an action that leads to\n",
        "        # high rewards (compared to critic's estimate) with high probability.\n",
        "        diff = ret - value\n",
        "        actor_losses.append(-log_prob * diff)  # actor loss\n",
        "\n",
        "        # The critic must be updated so that it predicts a better estimate of\n",
        "        # the future rewards.\n",
        "        critic_losses.append(\n",
        "            huber_loss(tf.expand_dims(value, 0), tf.expand_dims(ret, 0))\n",
        "        )\n",
        "\n",
        "    # Backpropagation\n",
        "    loss_value = sum(actor_losses) + sum(critic_losses)\n",
        "    grads = tape.gradient(loss_value, model_1.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model_1.trainable_variables))\n",
        "\n",
        "    # Clear the loss and reward history\n",
        "    # action_probs_history.clear()\n",
        "    # critic_value_history.clear()\n",
        "    # rewards_history.clear()\n",
        "\n",
        "# Log details\n",
        "episode_count += 1\n",
        "\n",
        "print(game.hand_players, game.hand_dealer)\n",
        "print('game.rewards\\t', game.rewards)\n",
        "print('state\\t\\t', state)\n",
        "print('action\\t\\t', action)\n",
        "print('critic_value_history', critic_value_history)\n",
        "print('rewards\\t\\t', rewards)\n",
        "print('episode_reward\\t', episode_reward)\n",
        "print('running_reward\\t', running_reward)\n",
        "print('returns\\t\\t', returns)\n",
        "print('loss_value\\t', loss_value)\n",
        "print('episode_count\\t', episode_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-335-9c56f7029c11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactor_losses\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcritic_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;31m# Clear the loss and reward history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[1;32m    631\u001b[0m       \u001b[0mRuntimeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcross\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mreplica\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m     \"\"\"\n\u001b[0;32m--> 633\u001b[0;31m     \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_empty_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m     \u001b[0mvar_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/utils.py\u001b[0m in \u001b[0;36mfilter_empty_gradients\u001b[0;34m(grads_and_vars)\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfiltered\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mvariable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     raise ValueError(f\"No gradients provided for any variable: {variable}. \"\n\u001b[0m\u001b[1;32m     74\u001b[0m                      f\"Provided `grads_and_vars` is {grads_and_vars}.\")\n\u001b[1;32m     75\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mvars_with_empty_grads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No gradients provided for any variable: (['dense_74/kernel:0', 'dense_74/bias:0', 'dense_75/kernel:0', 'dense_75/bias:0', 'dense_76/kernel:0', 'dense_76/bias:0'],). Provided `grads_and_vars` is ((None, <tf.Variable 'dense_74/kernel:0' shape=(7, 14) dtype=float32, numpy=\narray([[-0.58197254,  0.0655007 ,  0.30486423, -0.40047544,  0.19839096,\n         0.22482434, -0.22581887, -0.08178493,  0.1793508 ,  0.07421444,\n        -0.35264638,  0.4331597 , -0.42199582,  0.6036866 ],\n       [-0.17796452,  0.36013022, -0.19910589,  0.22690839,  0.15704226,\n         0.18279621, -0.2381826 ,  0.32716113,  0.27151853,  0.11683308,\n        -0.5690802 , -0.12525705,  0.18554634,  0.6189724 ],\n       [-0.3021521 ,  0.25022933,  0.3364063 ,  0.08987975,  0.3091067 ,\n         0.3599489 , -0.33489126,  0.3838228 , -0.07129928, -0.38958335,\n        -0.0427613 , -0.09943193, -0.09828579,  0.33179516],\n       [ 0.34371772,  0.18317339,  0.08548761,  0.42164713, -0.41384345,\n         0.3968484 ,  0.40313315, -0.2962972 , -0.3460298 ,  0.46512836,\n         0.3708045 , -0.46405065,  0.489763  ,  0.49376976],\n       [-0.34356484, -0.5302567 ,  0.07695484, -0.09656072, -0.29154152,\n        -0.30043578,  0.02390677, -0.37800157,  0.27885395, -0.5095297 ,\n        -0.3504601 , -0.11742112, -0.3424449 ,  0.21098614],\n       [ 0.423251  , -0.3996542 , -0.4367746 , -0.48486012,  0.52326137,\n        -0.4031273 , -0.37371275,  0.34905905,  0.2435106 , -0.1793615 ,\n         0.12357745,  0.3320741 ,  0.45043224, -0.20000568],\n       [-0.18948987,  0.07339025, -0.3564504 , -0.29065958,  0.14952862,\n         0.09933818, -0.32481116, -0.41521612, -0.30342185, -0.21695101,\n        -0.25682694,  0.2001639 , -0.1323531 ,  0.5147627 ]],\n      dtype=float32)>), (None, <tf.Variable 'dense_74/bias:0' shape=(14,) dtype=float32, numpy=\narray([-0.09999923,  0.09999873, -0.0999983 , -0.09999925,  0.        ,\n        0.09982457, -0.09999663,  0.        ,  0.        ,  0.09999888,\n       -0.09999935,  0.        ,  0.0999989 ,  0.09999926], dtype=float32)>), (None, <tf.Variable 'dense_75/kernel:0' shape=(14, 2) dtype=float32, numpy=\narray([[-0.37915707, -0.05648965],\n       [ 0.1695528 , -0.4122501 ],\n       [-0.32924753, -0.17208931],\n       [-0.34415057,  0.05065286],\n       [-0.23049435, -0.29209888],\n       [ 0.27080184, -0.10545301],\n       [ 0.59565014,  0.32718134],\n       [ 0.524067  , -0.07127941],\n       [ 0.45727295, -0.20813781],\n       [-0.44564897, -0.31518558],\n       [-0.58479464,  0.6014748 ],\n       [-0.39367747, -0.48769844],\n       [ 0.3014685 ,  0.00212461],\n       [ 0.59662133, -0.5266801 ]], dtype=float32)>), (None, <tf.Variable 'dense_75/bias:0' shape=(2,) dtype=float32, numpy=array([1.2566632e-13, 0.0000000e+00], dtype=float32)>), (None, <tf.Variable 'dense_76/kernel:0' shape=(14, 1) dtype=float32, numpy=\narray([[ 0.31265017],\n       [-0.34767163],\n       [ 0.08440956],\n       [ 0.32069975],\n       [ 0.02692401],\n       [-0.10179934],\n       [-0.00635812],\n       [-0.3810291 ],\n       [ 0.5314618 ],\n       [-0.37811294],\n       [ 0.37761468],\n       [ 0.5195418 ],\n       [-0.38440824],\n       [-0.52448094]], dtype=float32)>), (None, <tf.Variable 'dense_76/bias:0' shape=(1,) dtype=float32, numpy=array([-0.09999968], dtype=float32)>))."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oq328kfBMNuK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}